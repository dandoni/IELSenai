{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando a regionalidade do SESI, poderiamos combinar os dados do pysus com ibge atraves \n",
    "from pysus.online_data import IBGE\n",
    "pop = IBGE.get_population(source=\"POP\", year=2010)\n",
    "pop\n",
    "Ou simplesmente regionalizar o estudo, aqui se der tempo vou tentar ver o que tem maior ocorrencia por estado e plotar em barras empilhadas com numero de casos/pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install datasus-fetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement pandas-dbc (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for pandas-dbc\n"
     ]
    }
   ],
   "source": [
    "pip install pandas-dbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasus_fetcher\n",
    "import os\n",
    "import pandas as pd\n",
    "import dbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Exemplo de pré-processamento para a seleção de colunas\n",
    "df_cluster = df_acgr_cru[['DT_NOTIFIC', 'SG_UF_NOT',   'ANO_NASC', 'NU_IDADE_N', 'CS_SEXO', 'CS_GESTANT', 'CS_RACA', 'CS_ESCOL_N', 'ID_OCUPA_N', \n",
    "                           'SIT_TRAB', 'NUTEMPO', 'TPTEMPO', 'LOCAL_ACID', 'UF_EMP', 'MUN_EMP', \n",
    "                           'TERCEIRIZA', 'HORA_JOR', 'MIN_JOR', 'TIPO_ACID']]\n",
    "\n",
    "# Convertendo colunas de data\n",
    "df_cluster['DT_NOTIFIC'] = pd.to_datetime(df_cluster['DT_NOTIFIC'])\n",
    "df_cluster['Ano_Mes'] = df_cluster['DT_NOTIFIC'].dt.to_period('M')\n",
    "\n",
    "df_cluster['NU_IDADE_N'] = decodifica_idade_SINAN(df_cluster.NU_IDADE_N, 'Y')\n",
    "\n",
    "# Convertendo as colunas numéricas para o tipo adequado\n",
    "numeric_cols = ['ANO_NASC', 'NUTEMPO', 'TPTEMPO', 'HORA_JOR', 'MIN_JOR', 'TERCEIRIZA']\n",
    "\n",
    "# Convertendo para numérico, forçando erros para NaN e tratando\n",
    "df_cluster[numeric_cols] = df_cluster[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "# Garantindo que as variáveis numéricas sejam tratadas como float\n",
    "df_cluster[numeric_cols] = df_cluster[numeric_cols].astype(float)\n",
    "\n",
    "# Tratando valores nulos nas variáveis numéricas\n",
    "df_cluster[numeric_cols] = df_cluster[numeric_cols].fillna(df_cluster[numeric_cols].mean())\n",
    "\n",
    "# Tratando valores nulos nas variáveis numéricas (preenchendo com a média)\n",
    "df_cluster[numeric_cols] = df_cluster[numeric_cols].fillna(df_cluster[numeric_cols].mean())\n",
    "\n",
    "\n",
    "\n",
    "# Codificando variáveis categóricas\n",
    "categorical_cols = ['SG_UF_NOT', 'ID_MUNICIP', 'ID_REGIONA', 'CS_SEXO', 'CS_GESTANT', 'CS_RACA', \n",
    "                    'CS_ESCOL_N', 'ID_OCUPA_N', 'SIT_TRAB', 'LOCAL_ACID', 'UF_EMP', 'MUN_EMP', \n",
    "                    'TIPO_ACID']\n",
    "\n",
    "# Preenchendo os valores nulos nas colunas categóricas (com o valor 'Desconhecido', por exemplo)\n",
    "df_cluster[categorical_cols] = df_cluster[categorical_cols].fillna('Desconhecido')\n",
    "\n",
    "\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "encoded_data = encoder.fit_transform(df_cluster[categorical_cols])\n",
    "\n",
    "# Transformando variáveis numéricas\n",
    "numeric_cols = ['ANO_NASC', 'NU_IDADE_N', 'NUTEMPO', 'TPTEMPO', 'HORA_JOR', 'MIN_JOR', 'TERCEIRIZA']\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df_cluster[numeric_cols])\n",
    "\n",
    "# Convertendo a matriz esparsa para uma matriz densa\n",
    "encoded_data_dense = encoded_data.toarray()\n",
    "\n",
    "# Combinando os dados transformados\n",
    "processed_data = np.concatenate([encoded_data_dense, scaled_data], axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
