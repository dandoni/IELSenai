{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos analisar cafe em grao sem torra com codigo CNM 0901.11.10 de acordo com https://portalunico.siscomex.gov.br/classif/#/nomenclatura/0901/expandida?h=cafe&palavraInteira=false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ETL vamos primeiro buscar os dados somente para isso na balança de importação e exportação\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como é .gov pedia autenticação, nesse caso baixei o .zip para ETL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CO_ANO;\"CO_MES\";\"CO_NCM\";\"CO_UNID\";\"CO_PAIS\";\"SG_UF_NCM\";\"CO_VIA\";\"CO_URF\";\"QT_ESTAT\";\"KG_LIQUIDO\";\"VL_FOB\";\"VL_FRETE\";\"VL_SEGURO\"'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set the chunk size\n",
    "chunk_size = 1000000  # Adjust this based on your memory capacity\n",
    "\n",
    "# Read the first chunk to inspect the columns\n",
    "chunk = pd.read_csv('IMP_COMPLETA.csv', chunksize=chunk_size)\n",
    "\n",
    "# Get the columns of the first chunk\n",
    "first_chunk = next(chunk)  # Get the first chunk\n",
    "print(first_chunk.columns)  # Print the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CO_ANO', 'CO_MES', 'CO_NCM', 'CO_UNID', 'CO_PAIS', 'SG_UF_NCM',\n",
      "       'CO_VIA', 'CO_URF', 'QT_ESTAT', 'KG_LIQUIDO', 'VL_FOB', 'VL_FRETE',\n",
      "       'VL_SEGURO'],\n",
      "      dtype='object')\n",
      "        CO_ANO  CO_MES   CO_NCM  CO_UNID  CO_PAIS SG_UF_NCM  CO_VIA  CO_URF  \\\n",
      "261177    1997       3  9011110       21      586        PR       7  910600   \n",
      "735062    1997       3  9011110       21      249        SP       1  817800   \n",
      "862044    1997       2  9011110       21      586        PR       7  910600   \n",
      "\n",
      "        QT_ESTAT  KG_LIQUIDO  VL_FOB  VL_FRETE  VL_SEGURO  \n",
      "261177     30000       30000   90000       300          0  \n",
      "735062       171      170859  284392     22250       1777  \n",
      "862044        50       50400   89040       460          0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set the chunk size\n",
    "chunk_size = 1000000  # Adjust this based on your memory capacity\n",
    "\n",
    "# Read the first chunk with the correct delimiter (semicolon)\n",
    "chunk_iter = pd.read_csv('IMP_COMPLETA.csv', chunksize=chunk_size, delimiter=';')\n",
    "\n",
    "# Get the columns of the first chunk\n",
    "first_chunk = next(chunk_iter)  # Get the first chunk\n",
    "print(first_chunk.columns)  # Print the column names\n",
    "\n",
    "# Now proceed with the search after checking the columns\n",
    "for chunk in pd.read_csv('IMP_COMPLETA.csv', chunksize=chunk_size, delimiter=';'):\n",
    "    if 9011110 in chunk['CO_NCM'].values:\n",
    "        resultado = chunk[chunk['CO_NCM'] == 9011110]\n",
    "        print(resultado)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processamento concluído. Registros filtrados salvos em: filtered_IMP_COMPLETA.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Caminho para o arquivo CSV\n",
    "csv_file_path = 'IMP_COMPLETA.csv'\n",
    "\n",
    "# CO_NCM específico que você deseja filtrar\n",
    "co_ncm_especifico = \"9011110\"\n",
    "\n",
    "# Nome do arquivo de saída\n",
    "output_file = f\"filtered_{csv_file_path.split('/')[-1]}\"\n",
    "\n",
    "# Tamanho do chunk\n",
    "chunk_size = 1000000  # Ajuste conforme necessário\n",
    "\n",
    "# Criar o arquivo de saída\n",
    "with open(output_file, mode='w', newline='', encoding='utf-8') as output_csv:\n",
    "    writer = None  # Variável para controlar a escrita do cabeçalho\n",
    "    # Ler o CSV em chunks\n",
    "    for chunk in pd.read_csv(csv_file_path, chunksize=chunk_size, delimiter=';', encoding='latin-1'):\n",
    "        # Filtrar o chunk pelo valor de CO_NCM\n",
    "        filtered_chunk = chunk[chunk['CO_NCM'].astype(str) == co_ncm_especifico]\n",
    "        \n",
    "        # Se o arquivo de saída estiver vazio, escrever o cabeçalho\n",
    "        if writer is None:\n",
    "            filtered_chunk.to_csv(output_csv, header=True, index=False, sep=';')\n",
    "            writer = True  # Garantir que a próxima vez não escreva o cabeçalho\n",
    "        else:\n",
    "            # Caso contrário, escrever apenas as linhas filtradas\n",
    "            filtered_chunk.to_csv(output_csv, header=False, index=False, sep=';')\n",
    "\n",
    "print(f\"Processamento concluído. Registros filtrados salvos em: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processamento concluído. Registros filtrados salvos em: filtered_EXP_COMPLETA.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Caminho para o arquivo CSV\n",
    "csv_file_path = 'EXP_COMPLETA.csv'\n",
    "\n",
    "# CO_NCM específico que você deseja filtrar\n",
    "co_ncm_especifico = \"9011110\"\n",
    "\n",
    "# Nome do arquivo de saída\n",
    "output_file = f\"filtered_{csv_file_path.split('/')[-1]}\"\n",
    "\n",
    "# Tamanho do chunk\n",
    "chunk_size = 1000000  # Ajuste conforme necessário\n",
    "\n",
    "# Criar o arquivo de saída\n",
    "with open(output_file, mode='w', newline='', encoding='utf-8') as output_csv:\n",
    "    writer = None  # Variável para controlar a escrita do cabeçalho\n",
    "    # Ler o CSV em chunks\n",
    "    for chunk in pd.read_csv(csv_file_path, chunksize=chunk_size, delimiter=';', encoding='latin-1'):\n",
    "        # Filtrar o chunk pelo valor de CO_NCM\n",
    "        filtered_chunk = chunk[chunk['CO_NCM'].astype(str) == co_ncm_especifico]\n",
    "        \n",
    "        # Se o arquivo de saída estiver vazio, escrever o cabeçalho\n",
    "        if writer is None:\n",
    "            filtered_chunk.to_csv(output_csv, header=True, index=False, sep=';')\n",
    "            writer = True  # Garantir que a próxima vez não escreva o cabeçalho\n",
    "        else:\n",
    "            # Caso contrário, escrever apenas as linhas filtradas\n",
    "            filtered_chunk.to_csv(output_csv, header=False, index=False, sep=';')\n",
    "\n",
    "print(f\"Processamento concluído. Registros filtrados salvos em: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CO_ANO  CO_MES   CO_NCM  CO_UNID  CO_PAIS SG_UF_NCM  CO_VIA  CO_URF  \\\n",
      "0    1997       3  9011110       21      586        PR       7  910600   \n",
      "1    1997       3  9011110       21      249        SP       1  817800   \n",
      "2    1997       2  9011110       21      586        PR       7  910600   \n",
      "3    2000       3  9011110       21      586        PR       7  910600   \n",
      "4    2000       9  9011110       21       97        AC       7  230151   \n",
      "\n",
      "   QT_ESTAT  KG_LIQUIDO  VL_FOB  VL_FRETE  VL_SEGURO   Label  \n",
      "0     30000       30000   90000     300.0        0.0  Import  \n",
      "1       171      170859  284392   22250.0     1777.0  Import  \n",
      "2        50       50400   89040     460.0        0.0  Import  \n",
      "3        75       75000  107813     375.0        0.0  Import  \n",
      "4       248       17360    2480     100.0        0.0  Import  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Caminho para os arquivos CSV\n",
    "imp_file_path = 'filtered_IMP_COMPLETA.csv'\n",
    "exp_file_path = 'filtered_EXP_COMPLETA.csv'\n",
    "\n",
    "# Ler os dois arquivos CSV\n",
    "imp_df = pd.read_csv(imp_file_path, delimiter=';', encoding='latin-1')\n",
    "exp_df = pd.read_csv(exp_file_path, delimiter=';', encoding='latin-1')\n",
    "\n",
    "# Adicionar a coluna 'Label' para identificar se é Import ou Export\n",
    "imp_df['Label'] = 'Import'\n",
    "exp_df['Label'] = 'Export'\n",
    "\n",
    "# Concatenar os dois dataframes\n",
    "merged_df = pd.concat([imp_df, exp_df], ignore_index=True)\n",
    "\n",
    "# Exibir as primeiras linhas do dataframe concatenado\n",
    "print(merged_df.head())\n",
    "\n",
    "# Salvar o dataframe concatenado em um novo arquivo CSV, se necessário\n",
    "merged_df.to_csv('merged_data_with_labels.csv', index=False, sep=';', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARA AMANHA, ENTENDER MELHOR ESSES DADOS, PENSAR EM COMO AVALIAR< ACHOQUE KG LIQUIDO E DANDO MERGE POR MES/ANO. \n",
    "\n",
    "CONFERIR AS TAABELAS QUE TINHA VISTO E FAZER ANALISE DE DADOS/ML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
